# Chat Agent con LLM - Laboratorio S12

AplicaciÃ³n web de chat inteligente que integra un Large Language Model (LLM) mediante la API de OpenAI, implementada con Spring Boot y dockerizada para facilitar su despliegue.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un agente de chat conversacional que:
- Se comunica con la API de OpenAI (GPT-3.5-turbo)
- Mantiene historial de conversaciones en base de datos SQLite
- Proporciona interfaz web responsive con Thymeleaf
- EstÃ¡ completamente dockerizado para portabilidad

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Backend**: Spring Boot 3.4.0
- **Frontend**: Thymeleaf, HTML5, CSS3, JavaScript
- **Base de datos**: SQLite con JPA/Hibernate
- **LLM**: OpenAI GPT-3.5-turbo
- **ContainerizaciÃ³n**: Docker y Docker Compose
- **Java**: JDK 21

## ğŸ“ Estructura del Proyecto

chat-agent/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main/
â”‚ â”‚ â”œâ”€â”€ java/com/example/chatagent/
â”‚ â”‚ â”‚ â”œâ”€â”€ controller/
â”‚ â”‚ â”‚ â”‚ â””â”€â”€ ChatController.java
â”‚ â”‚ â”‚ â”œâ”€â”€ service/
â”‚ â”‚ â”‚ â”‚ â””â”€â”€ ChatService.java
â”‚ â”‚ â”‚ â”œâ”€â”€ entity/
â”‚ â”‚ â”‚ â”‚ â””â”€â”€ Conversation.java
â”‚ â”‚ â”‚ â”œâ”€â”€ repository/
â”‚ â”‚ â”‚ â”‚ â””â”€â”€ ConversationRepository.java
â”‚ â”‚ â”‚ â””â”€â”€ ChatAgentApplication.java
â”‚ â”‚ â””â”€â”€ resources/
â”‚ â”‚ â”œâ”€â”€ application.properties
â”‚ â”‚ â”œâ”€â”€ templates/
â”‚ â”‚ â”‚ â””â”€â”€ chat.html
â”‚ â”‚ â””â”€â”€ static/js/
â”‚ â”‚ â””â”€â”€ chat.js
â”œâ”€â”€ data/
â”‚ â””â”€â”€ chat.db
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .dockerignore
â””â”€â”€ pom.xml


## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### Requisitos Previos

- Java 21+
- Maven 3.6+
- Docker y Docker Compose
- API Key de OpenAI

### ConfiguraciÃ³n

1. **Clonar el repositorio**:
   git clone <tu-repositorio>
   cd chat-agent
2. **Configurar API Key**:
   Editar `src/main/resources/application.properties`:
   openai.api.key=tu-api-key-aqui

### EjecuciÃ³n Local
Compilar
./mvnw clean package

Ejecutar
./mvnw spring-boot:run

Acceder a: http://localhost:8080

### EjecuciÃ³n con Docker
Construir imagen
docker-compose build

Ejecutar contenedor
docker-compose up

Ejecutar en segundo plano
docker-compose up -d

Detener
docker-compose down

## ğŸ¯ Funcionalidades

### 1. Chat Conversacional
- Interfaz web intuitiva y responsive
- EnvÃ­o de mensajes en tiempo real
- Respuestas generadas por GPT-3.5-turbo

### 2. Persistencia de Datos
- Historial completo de conversaciones
- Base de datos SQLite embebida
- Consultas por ID de usuario

### 3. Arquitectura de Microservicios
- SeparaciÃ³n clara de responsabilidades (MVC)
- Repository pattern con Spring Data JPA
- Service layer para lÃ³gica de negocio

### 4. DockerizaciÃ³n
- Imagen multi-stage para optimizaciÃ³n
- VolÃºmenes persistentes para datos
- Variables de entorno configurables

## ğŸ“Š Endpoints API

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/` | Interfaz principal del chat |
| POST | `/chat/send` | Enviar mensaje al LLM |
| GET | `/chat/history` | Obtener historial de conversaciÃ³n |

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

En `docker-compose.yml`:
environment:

SPRING_DATASOURCE_URL=jdbc:sqlite:/app/data/chat.db

OPENAI_API_KEY=tu-api-key

OPENAI_MODEL=gpt-3.5-turbo

### Base de Datos

SQLite configurado en `application.properties`:
spring.datasource.url=jdbc:sqlite:chat.db
spring.jpa.hibernate.ddl-auto=update

Ejecutar tests
./mvnw test

Con cobertura
./mvnw clean verify

## ğŸ“ Conclusiones

1. **IntegraciÃ³n exitosa** de LLM en aplicaciÃ³n web mediante API de OpenAI
2. **Arquitectura robusta** basada en patrones MVC y Repository
3. **Persistencia efectiva** de conversaciones con SQLite/JPA
4. **DockerizaciÃ³n completa** garantiza portabilidad y fÃ¡cil despliegue
5. **Experiencia de usuario** fluida con interfaz responsive

## ğŸ‘¨â€ğŸ’» Autor

**JosÃ© Carlos Vitorino Condori**
- TECSUP Arequipa
- Desarrollo de Software
- Laboratorio S12 - 2025

## ğŸ“„ Licencia

Este proyecto fue desarrollado con fines acadÃ©micos para el curso de Desarrollo de Software en TECSUP.





